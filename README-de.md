# ğŸ” Vision-Validator

**Deutsche Version** | [English Version](README.md)

Vision-Validator ist eine leistungsstarke Web-Anwendung zum Testen, Vergleichen und Anwenden von YOLO-Modellen fÃ¼r Objekterkennung und Instanzsegmentierung. Mit einer benutzerfreundlichen OberflÃ¤che kÃ¶nnen Sie verschiedene Modelle laden, Bilder analysieren und Live-Videostreams verarbeiten.

![Yolo Vision Interface](https://placeholder.image)

## âœ¨ Features

- ğŸ¯ **Multi-Model Support**: UnterstÃ¼tzt YOLO .pt, .onnx und .engine Modelle
- ğŸ“¸ **Live Camera Detection**: Echtzeit-Objekterkennung Ã¼ber Webcam
- ğŸ–¼ï¸ **Image Upload & Detection**: Bild-Upload fÃ¼r Batch-Verarbeitung
- ğŸ¨ **Instance Segmentation**: Pixel-genaue Objektumrisse
- âš™ï¸ **Anpassbare Einstellungen**: Konfidenz-Schwellenwerte, Maskenfarben und Transparenz
- ğŸ’¾ **Automatisches Speichern**: Erkannte Objekte werden lokal gespeichert
- ğŸ”„ **Model Management**: Upload, Umbenennen und LÃ¶schen von Modellen
- ğŸš€ **GPU-Beschleunigung**: Automatische GPU-Nutzung wenn verfÃ¼gbar
- ğŸ§¹ **Memory Management**: Automatische Speicherbereinigung fÃ¼r stabilen Betrieb

## ğŸ› ï¸ Installation

### Systemvoraussetzungen
- Python 3.8 oder hÃ¶her
- Webcam (optional, fÃ¼r Live-Erkennung)
- CUDA-fÃ¤hige GPU (optional, fÃ¼r Beschleunigung)

### Schritt 1: Repository klonen
```bash
git clone https://github.com/Loky-Coffee/Yolo-Vision.git
cd Yolo-Vision
```

### Schritt 2: Virtual Environment erstellen
```bash
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
```

### Schritt 3: AbhÃ¤ngigkeiten installieren

FÃ¼r CPU-only Installation:
```bash
pip install -r requirements.txt
```

FÃ¼r GPU-Beschleunigung (CUDA 11.8):
```bash
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
pip install -r requirements.txt
```

### Schritt 4: Anwendung starten
```bash
python app.py
```

Die Anwendung ist nun unter http://localhost:5000 verfÃ¼gbar.

## ğŸ“ Projektstruktur

```
Yolo-Vision/
â”œâ”€â”€ app.py                  # Hauptanwendung
â”œâ”€â”€ requirements.txt        # Python-AbhÃ¤ngigkeiten
â”œâ”€â”€ models/                 # Modell-Speicher
â”œâ”€â”€ uploads/               # Hochgeladene Bilder
â”œâ”€â”€ results/               # Erkennungsergebnisse
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html         # Frontend-Template
â””â”€â”€ README.md              # Diese Datei
```

## ğŸš¦ Erste Schritte

### 1. Modell hochladen
- Klicken Sie auf "Choose File" um ein YOLO-Modell (.pt, .onnx, .engine) auszuwÃ¤hlen
- Das Modell wird automatisch erkannt und geladen

### 2. Objekterkennung

**FÃ¼r Bilder:**
- Klicken Sie auf "Choose Image File"
- WÃ¤hlen Sie ein Bild aus
- Klicken Sie auf "Detect"
- Das Ergebnis wird angezeigt

**FÃ¼r Live-Video:**
- Stellen Sie sicher, dass eine Webcam angeschlossen ist
- Das Live-Feed wird automatisch gestartet
- Erkannte Objekte werden automatisch markiert und gespeichert

### 3. Einstellungen anpassen
- **Confidence Threshold**: Mindestwahrscheinlichkeit fÃ¼r Erkennungen (0-1)
- **Camera Resolution**: Webcam-AuflÃ¶sung einstellen
- **Mask Color**: Farbe der Segmentierungsmasken
- **Mask Alpha**: Transparenz der Masken
- **Model Input Size**: EingabegrÃ¶ÃŸe fÃ¼r das Modell

## ğŸ® Verwendung

### Modell-Management
```python
# Modell laden
POST /load_model
{
    "model_index": 0  # Index des Modells in der Liste
}

# Modell umbenennen
POST /rename_model
{
    "model_index": 0,
    "new_name": "my_model.pt"
}

# Modell lÃ¶schen
POST /delete_model/0  # Model index
```

### Erkennung
```python
# Bild-Erkennung
POST /detect_image
Files: {'image': file}

# Cooldown zurÃ¼cksetzen
POST /reset_cooldown
```

## âš™ï¸ Konfiguration

### Einstellungen in app.py
```python
settings = {
    'conf_threshold': 0.5,      # Konfidenz-Schwellenwert
    'camera_width': 1280,       # Kamera-Breite
    'camera_height': 720,       # Kamera-HÃ¶he
    'mask_alpha': 0.5,          # Masken-Transparenz
    'mask_color': '#FF0000',    # Masken-Farbe (Hex)
    'model_input_width': 640,   # Modell-Eingabebreite
    'model_input_height': 640   # Modell-EingabehÃ¶he
}
```

## ğŸ› Fehlerbehandlung

### HÃ¤ufige Probleme

**Kamera nicht erkannt:**
- ÃœberprÃ¼fen Sie Berechtigungen
- Stellen Sie sicher, dass die Kamera nicht von einer anderen Anwendung verwendet wird
- SchlieÃŸen Sie andere Tabs, die die Kamera verwenden kÃ¶nnten
- Testen Sie mit: `cv2.VideoCapture(0)`

**Modell lÃ¤dt nicht:**
- ÃœberprÃ¼fen Sie KompatibilitÃ¤t (YOLO Format)
- Stellen Sie ausreichend RAM/VRAM sicher

**GPU nicht erkannt:**
```bash
python -c "import torch; print(torch.cuda.is_available())"
```

### Logs
Anwendung mit Logging starten:
```bash
python app.py 2>&1 | tee app.log
```

## ğŸš€ Performance-Optimierung

- **GPU verwenden**: Automatisch wenn CUDA verfÃ¼gbar
- **Modelloptimierung**: TensorRT-Modelle (.engine) fÃ¼r beste Performance
- **Speicherverwaltung**: Automatische Bereinigung alle 5 Minuten
- **Frame-Rate**: Angepasst auf 30 FPS fÃ¼r flÃ¼ssige Anzeige

## ğŸ”’ Sicherheit

- Automatische Bereinigung alter Dateien (max. 20)
- Sichere Datei-Uploads
- Thread-sichere Operationen
- Speicher-Lecks werden automatisch behoben

## ğŸ“š Verwendete Technologien

- **Backend**: Flask, OpenCV, PyTorch, Ultralytics
- **Frontend**: HTML, JavaScript, Bootstrap
- **Computer Vision**: YOLO, OpenCV
- **Threading**: Python threading, concurrent.futures

## ğŸ¤ Mitwirken

BeitrÃ¤ge sind willkommen! Bitte erstellen Sie einen Fork und Ã¶ffnen Sie eine Pull Request.

## ğŸ“„ Lizenz

MIT License - siehe LICENSE Datei fÃ¼r Details.

## ğŸ™ Danksagungen

- [Ultralytics YOLO](https://github.com/ultralytics/ultralytics)
- [OpenCV Community](https://opencv.org/)
- Alle Mitwirkenden und Tester

Entwickelt mit â¤ï¸ von [Loky Coffee](https://github.com/Loky-Coffee)